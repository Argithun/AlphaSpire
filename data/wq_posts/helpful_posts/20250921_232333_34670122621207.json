{
  "title": "【MCP Workflow】一个自动化找alpha的工作流分享",
  "description": "先看一下效果，目前跑的效果不错，我使用codex和claude code跑，都可以获得不错的效果，简单贴一张效果图  可结合之前的帖子...",
  "post_body": "先看一下效果，目前跑的效果不错，我使用codex和claude code跑，都可以获得不错的效果，简单贴一张效果图\n可结合之前的帖子\nhttps://support.worldquantbrain.com/hc/en-us/community/posts/34208186164631-%E6%9D%A5%E8%87%AAMCP%E7%9A%84operator%E6%8C%87%E5%8C%97-%E7%BB%88%E4%BA%8E%E7%9C%8B%E6%87%82%E4%BA%86%E5%A4%A7%E5%A4%9A%E6%95%B0%E7%9A%84%E5%B9%B3%E5%8F%B0operator\n一并喂给AI，可减少由于操作符引起的错误\n工作流程如下：\n# Alpha 开发工作流（D1 版）\n## 🎯 目标与范围（顾问标准）\n- 目标：在 D1 设置下，系统化发现 Sharpe 与 Fitness 达标、可提交生产的 Alpha。\n- 成功标准（顾问提交门槛）：\n- Sharpe > 1.58；Fitness > 1.0。\n- Turnover 在 1%–70%；单票最大权重 <10%。\n- 需通过 Sub-Universe、自相关（Self-corr）与全平台相关（Prod-corr）测试；IS-Ladder（D1）阈值：Fail=1.59；2–5年≥2.38；6年≥2.22；7年≥2.06；8年≥1.90；9年≥1.74；10年≥1.59。\n## 📦 标准参数获取（MCP）\n- 使用 `get_platform_setting_options` 查询可用组合（instrument_type/region/delay/universe/neutralization），据此设置回测参数。\n- USA：以 D1 为默认；选择液体类 universe（如 TOP 系列）。\n- ASI：仅支持 D1；`universe=MINVOL1M/ILLIQUID_MINVOL1M`；`max_trade=ON` 必须开启。\n- 通用：`language=FASTEXPR`、`pasteurization=ON`；其余按平台建议。\n## ✅ Step 0 预检清单\n- 认证：完成平台登录（401 需重新认证）。\n- 数据：确认目标数据集可访问；统计字段 coverage、userCount、类型（MATRIX/VECTOR/GROUP）。\n- 参数：使用 `get_platform_setting_options` 自检参数组合合法性，避免 400。\n- 表达式：字段存在性、类型匹配（VECTOR 需 `vec_sum/vec_avg` 聚合）、语法检查。\n- 时间窗口规范：`ts_*` 仅允许 {5, 22, 66, 126, 255}（周、月、季、半年、年），不使用其他窗口。\n## 🔍 Phase 1 数据集分析（字段优选）\n- 选择标准：\n- coverage ≥ 0.4 优先；\n- userCount 适中（避开极高拥挤与极低稀缺）；\n- 类型以 MATRIX 为主，VECTOR 先聚合再用，GROUP 用于分组/中性化。\n- 分层：A+（高优先）、B（次优先）、C（探索）。\n## 🚀 Phase 2 初次批量验证（8个/批）\n- 强约束：仅使用加、减、乘、除四则运算两两组合；每个表达式恰好两个字段；同批尽量不重复字段对；字段限 MATRIX；延迟一致（D1）。\n- 缺失与异常的最小化处理：\n- 允许 `ts_backfill(x, d, k=1, ignore=\"NAN\")`，d ∈ {5, 22, 66, 126, 255}；\n- 允许 `add/subtract/multiply` 的 `filter=true`；\n- 允许在最外层一次 `pasteurize(expr)`。\n- 规模与门槛（初次抽样）：\n- 先生成并测试约 100 个两两组合（8/批，共约 13 批）。\n- 目标：累计找到 ≥10 个组合满足 Sharpe≥0.8 且 Fitness≥0.6。\n- 若未达标：替换/扩充字段池、调整字段配对方式，重复 Phase 2，直至达标。\n- 示例（占位，替换 field1…field16）：\n```text\nfield1 + field2\nfield3 - field4\nfield5 * field6\nfield7 / field8\nfield9 + field10\nfield11 - field12\nfield13 * field14\nfield15 / field16\n```\n- 示例（带缺失值处理）：\n```text\npasteurize(field1 / ts_backfill(field2, 22))\nadd(ts_backfill(field1, 22), field2, true)\nsubtract(field1, ts_backfill(field2, 66), true)\nmultiply(ts_backfill(field1, 22), field2, true)\n```\n## 📈 Phase 3 评估与闸门（不做参数微调）\n- 单批评估：\n- max_sharpe ≥ 1.0 → 进入 Phase 4 做模板验证。\n- 0.8 ≤ max_sharpe < 1.0 → 记录为候选，优先探索其他字段对；达标后再进入 Phase 4。\n- 0.5 ≤ max_sharpe < 0.8 → 直接转换到其他字段类型或主题。\n- max_sharpe < 0.5 → 立即放弃并记录。\n- 推进门槛：累计 ≥10 个 Sharpe≥0.8 & Fitness≥0.6 的组合后进入 Phase 4。\n## 🔧 Phase 4 模板检索与验证（MCP）\n- 模板来源：`get_documentations`（Alpha Examples 等）、`search_forum_posts`（按数据集/字段/主题）、内部模板库。\n- 字段映射（用 `get_datafields` 校验）：MATRIX 直用；VECTOR 先 `vec_avg/vec_sum`；GROUP 仅做 `group_*`/`neutralize`；ts 窗口仅 {5, 22, 66, 126, 255}。\n- 批次生成（8/批）：跨模板家族取样，不做参数微调。\n- 模板家族与示例（占位）：\n- 分组排序：`group_rank(x, industry)`、`group_rank(x, subindustry)`\n- 分组标准化：`group_zscore(x, industry)`\n- 单层中性化：`group_neutralize(zscore(x), industry)`\n- 双层中性化：`group_neutralize(group_neutralize(x, industry), bucket(cap, 10))`\n- 截面标准化：`winsorize(zscore(x), 4)`、`quantile(zscore(x), driver=gaussian)`\n- 向量中性化：`vector_neut(x, y)`\n- 执行与评估：用 `create_multiSim`（8/批）回测，ASI 确保 `max_trade=ON`；按 Phase 3 闸门判断。\n## 🔁 迭代与回退策略\n- 触发：Phase 2 未达 10 个候选，或 Phase 4/5 未过顾问门槛/IS-Ladder/Sub-Universe/Self/Prod-Corr/区域特定测试。\n- 回退：返回 Phase 2 更新字段池，重采样约 100 个组合并重试；保留有效模板家族方向，优先更换底层字段/主题。\n- 执行循环：通过 MCP 工具实现 Phase 2 采样与 `create_multiSim` → Phase 3 闸门 → Phase 4 模板检索与回测 → Phase 5 顾问测试；未通过则回退。\n## 🧮 Phase 5 去重、多样性与稳健性\n- 相关性：对内/外部 Alpha 做相关性筛选（|ρ| < 0.3）。\n- 多样性：覆盖不同数据主题/字段家族/操作符族。\n- 稳健性：\n- OS 验证与滚动窗口；逐年一致性（Sharpe/IC）；分位单调性；换手与成本敏感性。\n- D0/D1 交叉自检：如字段也有 D0 数据，可做 D0 自检（非必需）。\n- 区域特异：ASI 需 Robust Universe Test（返回与 Sharpe ≥90%），max_trade=ON。\n## 🗂️ Phase 6 文档化与资产化\n- 记录：批次ID、表达式、参数、指标（Sharpe/Fitness/turnover/IC/年化/回撤）。\n- 属性：为成功 Alpha 设置 name/tags/描述（dataset/fields/operators/neutralization/delay）。\n- 沉淀：更新字段质量库与模板库。\n## 📚 MCP 调用指引（汇总）\n- 参数与可选项：`get_platform_setting_options`\n- 数据集与字段：`get_datasets`、`get_datafields`\n- 模板与学习材料：`get_documentations`\n- 论坛模板搜索：`search_forum_posts`\n- 多表达式回测：`create_multiSim`（8/批）\n- 相关性与提交检查：`check_correlation`、`get_submission_check`",
  "post_comments": [
    "开始工作流的方式：\n按照工作流，对 GLB analyst进行探索 @workflow.md 可用操作符参见 @operators.json 运行过程中，不要停下，直到完成目标",
    "因为这个工作流是在codex下完成的，同时最近claude code总有不同程度的降智，所以用codex跑起来效果反而比cc更好，codex配置MCP的方式，和其他JSON形式不同，codex使用/.codex/config.toml文件进行配置，配置方式如下：\n[mcp_servers.wqb_mcp]\ncommand = \"python\"\nargs = [\"your_path/cnhkmcp/untracked/platform_functions.py\"]\ndescription = \"WorldQuant BRAIN Platform MCP Server - Core tools for interacting with the BRAIN platform, including simulation, alpha management, and data access. Credentials are stored in user_config.json.\"",
    "您好，大佬，你上面说的可用操作符参见的operators.json这个文件内容是什么，能展示下吗",
    "大佬的工作流，看着就很清晰明了， 至少我看懂， 我想AI 也能明白， 只要调好 工具即可。\n就看实测中工作流消耗的token 有多少， 是不是可以再把固定的工作流，再固化成为代码，只效给AI 做探索，做经济直觉 工作？",
    "感谢佬的分享",
    "今天用AWS的 Kiro 试了一下，能进行回测，但是经常会报MCP 超时的错误， 要求等待十分钟 ， 但还是时常会报错。\n目前流程上大致能模仿流程，也能回测，但是不能持续进行，最终失败了。\n目前有两点小结：\n1. 一直用AI 执行需要确定性事务不是明智选择， 2. 持续进行消耗的Token较大，这样成本会很高。\n所以我会将AI作为理解Alpha 字段的工具， 做模板可行性的验证，至于持续加回测的活，还是效给固定的硬编码。",
    "太强了！！感谢FF大佬的无私分享，这简直是一份保姆级的D1 Alpha开发手册，把MCP工作流的价值体现得淋漓尽致。\n我之前自己摸索的时候，最大的痛点就是整个流程是散装的、碰运气的。要么在字段选择上就卡住了，不知道如何系统性地筛选；要么就是乱试一堆表达式，回测效率极低，好不容易有一个Sharpe看起来还不错的，一做相关性检验或者IS-Ladder测试就废了，时间全浪费了。您这个工作流直接把整个过程工业化、系统化了，尤其是\nPhase 2的“两两四则运算”初筛\n和\n明确的闸门标准\n，我觉得这是整个流程最精髓的地方！先用一个成本极低的方式快速海选“潜力股”，而不是一上来就套复杂的模板，这个思路真的解决了大问题，能节省巨量的时间和算力。\n另外，您把顾问级别的\n实战门槛和避坑指南\n都揉进去了，这点对我们来说太关键了。比如ASI必须开\nmax_trade=ON\n、时间窗口必须用特定值、还有IS-Ladder不同年份的具体阈值，这些细节如果没人总结，自己踩坑可能要交不少“学费”。把它和之前那篇Operator指南结合食用，相当于既给了地图（工作流），又给了操作说明书（Operator详解），可靠性瞬间就上来了。\n我已经准备按照这个框架把自己的流程重构一下了，感觉有了这个“标尺”，Alpha开发从一种“玄学”变得更像一门“科学”了。再次感谢分享，期待您更多的实战心得！",
    "=============================感谢大佬分享=====================================\n请问这个方式是通过MCP进行提交回测的，那么效率如何呢，一般来说大模型都有最大Token的概念，那么一般可以提交几轮呢？我在想，是否可以有一种方式，让大模型在提交模拟等待的时候继续思考，而非停滞，这样是不是更能加快效率呢？\n“\n- USA：以 D1 为默认；选择液体类 universe（如 TOP 系列）。\n”\n请问此处的液体类是什么意思呢？\n=============================感谢大佬分享=====================================",
    "感谢分享",
    "BW16434\n就是平台文档，也可参考之前的发帖\n来自MCP的operator指北\nMCP中也内置了这个方法，可以直接让AI把它抓下来，沉淀为一个文档，后续直接让AI使用这个文档，没有必要让AI每次都去拿，这样一方面提升效率，另一方面也节约Token。希望对你有帮助。",
    "ZZ37826\n流动性排名，比如TOP3000，就是流动性最高的3000只股票，这个工作流是通过AI总结经验不断修订的，其中部分内容是AI自行修订的，而AI的原始回答是英文，我让他翻译成了中文，所以其中会有一些不太正确的翻译",
    "关于之前在群里分享的使用手机远程操作MCP，主要通过开源项目\nhappy\n实现，可以直接参考链接中的官方文档，也可参考下面这个帖子，之前说在这里更新，最终发成了一篇帖子，这里指个路\n【随时随地MCP】一个在手机上远程使用MCP的方案\n===============================================================================================================",
    "还有一点需要注意，这个工作流主要研究对象为atom，所以前文提到使用四则运算是没问题的，但是对于跨数据集，这里就需要改一下，要强制ai给出有经济学含义的组合，否则存在很大的过拟合风险，特别注意\n------------------------------------------------------------",
    "感谢您的分享。对于字段进行四则运算，这个想法很有趣。我也去尝试一下。虽然表达式是否有经济学含义值得商榷，看看是不是能够做出信号。",
    "感謝大佬无私的分享~~!\n-----------------------------------------------------------------------------------------------------"
  ]
}