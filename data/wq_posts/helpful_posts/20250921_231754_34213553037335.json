{
  "title": "【MCP WorkFlow】一个使用MCP来给Alpha写描述并获取更多启发的工作流",
  "description": "我们都知道，要发挥MCP的功能，就需要把它当作我们的秘书。以下是一个参考工作流，你可以让它照着做，并把Alpha表达式和Region给它，就能给你Alpha进行解释，并给你进一步点塔的启发，和撰写description的台词。 Alpha Explanation...",
  "post_body": "我们都知道，要发挥MCP的功能，就需要把它当作我们的秘书。以下是一个参考工作流，你可以让它照着做，并把Alpha表达式和Region给它，就能给你Alpha进行解释，并给你进一步点塔的启发，和撰写description的台词。\nAlpha Explanation Workflow\nThis manual provides a step-by-step workflow for analyzing and explaining a WorldQuant BRAIN alpha expression. By following this guide, you can efficiently gather the necessary information to understand the logic and potential strategy behind any alpha.\nStep 1: Deconstruct the Alpha Expression\nThe first step is to break down the alpha expression into its fundamental components:\ndata fields\nand\noperators\n.\nFor example, given the expression\nquantile(ts_regression(oth423_find,group_mean(oth423_find,vec_max(shrt3_bar),country),90))\n:\nData Fields:\noth423_find\n,\nshrt3_bar\nOperators:\nquantile\n,\nts_regression\n,\ngroup_mean\n,\nvec_max\nStep 2: Analyze Data Fields\nUse the\nbrain-platform-mcp\ntool\nget_datafields\nto get detailed information about each data field.\nTool Usage:\nxml <use_mcp_tool> <server_name>brain-platform-mcp</server_name> <tool_name>get_datafields</tool_name> <arguments> { \"instrument_type\": \"EQUITY\", \"region\": \"ASI\", \"delay\": 1, \"universe\": \"MINVOL1M\", \"data_type\": \"VECTOR\", \"search\": \"shrt3_bar\" } </arguments> </use_mcp_tool>\nTips for effective searching:\nSpecify Parameters:\nAlways provide as much information as you know, including\ninstrument_type\n,\nregion\n,\ndelay\n,\nuniverse\n, and\ndata_type\n(\nMATRIX\nor\nVECTOR\n).\nIterate:\nIf you don't find the data field on your first try, try different combinations of parameters. The\nASI\nregion, for example, has two universes:\nMINVOL1M\nand\nILLIQUID_MINVOL1M\n.\nCheck Data Type:\nBe sure to check if the data is a\nMATRIX\n(one value per stock per day) or a\nVECTOR\n(multiple values per stock per day). This is crucial for understanding how the data is used.\nExample Data Field Information:\noth423_find\n: A\nmatrix\ndata field from the \"Fundamental Income and Dividend Model\" dataset in the ASI region. It represents a \"Find score,\" likely indicating fundamental attractiveness.\nshrt3_bar\n: A\nvector\ndata field from the \"Securities Lending Files Data\" dataset in the ASI region. It provides a vector of ratings (1-10) indicating the demand to borrow a stock, which is a proxy for short-selling interest.\nStep 3: Understand the Operators\nUse the\nbrain-platform-mcp\ntool\nget_operators\nto get a list of all available operators and their descriptions.\nTool Usage:\nxml <use_mcp_tool> <server_name>brain-platform-mcp</server_name> <tool_name>get_operators</tool_name> <arguments> {} </arguments> </use_mcp_tool>\nThe output of this command contains a wealth of information. For your convenience, a table of the most common operators is included in the Appendix of this manual.\nStep 4: Consult Official Documentation\nFor more complex topics, the official BRAIN documentation is an invaluable resource. Use the\nget_documentations\ntool to see a list of available documents, and\nget_documentation_page\nto read a specific page.\nExample:\nTo understand vector data fields better, I consulted the \"Vector Data Fields ðŸ¥‰\" document (\nvector-datafields\n). This revealed that vector data contains multiple values per instrument per day and must be aggregated by a vector operator before being used with other operators.\nStep 5: Broaden Understanding with External Research (Optional)\nFor cutting-edge ideas and inspiration, you can search for academic papers on arXiv using the provided\narxiv_api.py\nscript.\nWorkflow:\nIdentify Keywords:\nBased on your analysis of the alpha, identify relevant keywords. For our example, these were:\n\"short interest\"\n,\n\"fundamental analysis\"\n,\n\"relative value\"\n, and\n\"news sentiment\"\n.\nRun the Script:\nUse the\nwith-wrappers\nscript to avoid SSL errors.\npython arxiv_api.py \"your keywords here\" -n 10\nStep 6: Synthesize and Explain\nOnce you have gathered all the necessary information, structure your explanation in a clear and concise format. The following template is recommended:\nIdea:\nA high-level summary of the alpha's strategy.\nRationale for data used:\nAn explanation of why each data field was chosen and what it represents.\nRationale for operators used:\nA step-by-step explanation of how the operators transform the data to generate the final signal.\nFurther Inspiration:\nIdeas for new alphas based on your research.\nTroubleshooting\nSSL Errors:\nIf you encounter a\nCERTIFICATE_VERIFY_FAILED\nerror when running python scripts that access the internet, use the\nAI to help you change or make\nscript to execute your command.\nAppendix A: Understanding Vector Data\nVector Data is a distinct type of data field where the number of events recorded per day, per instrument, can vary. This is in contrast to standard matrix data, which has a single value for each instrument per day.\nFor example, news sentiment data is often a vector because a stock can have multiple news articles on a single day. To use this data in most BRAIN operators, it must first be aggregated into a single value using a\nvector operator\n.",
  "post_comments": [
    "撰写类似文章，可以获得更快审批，高价值优秀者可获得礼物。",
    "中文版：Alpha 解析工作流程\n本手册提供了逐步的工作流程，用于分析和解释 WorldQuant BRAIN alpha 表达式。按照本指南操作，你可以高效地收集所需信息，理解任何 alpha 背后的逻辑和潜在策略。\n第一步：拆解 Alpha 表达式\n第一步是将 alpha 表达式分解为其基本组成部分：数据字段和运算符。\n例如，给定表达式：\nquantile(ts_regression(oth423_find,group_mean(oth423_find,vec_max(shrt3_bar),country),90))\n数据字段\n：oth423_find, shrt3_bar\n运算符\n：quantile, ts_regression, group_mean, vec_max\n第二步：分析数据字段\n使用 brain-platform-mcp 工具的\nget_datafields\n功能，获取每个数据字段的详细信息。\n工具用法：\n<use_mcp_tool>\n  <server_name>brain-platform-mcp</server_name>\n  <tool_name>get_datafields</tool_name>\n  <arguments>\n    { \"instrument_type\": \"EQUITY\", \"region\": \"ASI\", \"delay\": 1, \"universe\": \"MINVOL1M\", \"data_type\": \"VECTOR\", \"search\": \"shrt3_bar\" }\n  </arguments>\n</use_mcp_tool>\n高效搜索技巧：\n指定参数\n：尽可能提供已知信息，包括 instrument_type、region、delay、universe 和 data_type（MATRIX 或 VECTOR）。\n多次尝试\n：如果第一次没有找到数据字段，尝试不同参数组合。例如，ASI 区域有两个 universe：MINVOL1M 和 ILLIQUID_MINVOL1M。\n检查数据类型\n：务必确认数据是 MATRIX（每只股票每天一个值）还是 VECTOR（每只股票每天多个值）。这对于理解数据的使用方式至关重要。\n示例数据字段信息：\noth423_find\n：来自 ASI 区域“Fundamental Income and Dividend Model”数据集的矩阵型数据字段。代表“Find score”，可能表示基本面吸引力。\nshrt3_bar\n：来自 ASI 区域“Securities Lending Files Data”数据集的向量型数据字段。提供 1-10 的评级向量，表示借入股票的需求，是做空兴趣的代理指标。\n第三步：理解运算符\n使用 brain-platform-mcp 工具的\nget_operators\n功能，获取所有可用运算符及其说明。\n工具用法：\n<use_mcp_tool>\n  <server_name>brain-platform-mcp</server_name>\n  <tool_name>get_operators</tool_name>\n  <arguments>{}</arguments>\n</use_mcp_tool>\n该命令的输出包含大量信息。为方便起见，本手册附录中包含了最常用运算符的表格。\n第四步：查阅官方文档\n对于更复杂的主题，官方 BRAIN 文档是宝贵的资源。使用\nget_documentations\n工具查看可用文档列表，使用\nget_documentation_page\n阅读特定页面。\n示例\n：为了更好地理解向量数据字段，我查阅了“Vector Data Fields”文档（vector-datafields）。了解到向量数据每个标的每天可以有多个值，必须先用向量运算符聚合后才能与其他运算符一起使用。\n第五步：通过外部研究拓宽理解（可选）\n为了获得前沿思路和灵感，可以在论坛搜索他人的相关见解，或使用提供的 arxiv_api.py 脚本在 arXiv 上搜索学术论文。\n工作流程：\n确定关键词\n：根据对 alpha 的分析，确定相关关键词。例如本例为：“short interest”、“fundamental analysis”、“relative value”、“news sentiment”。\n运行脚本\n：使用 with-wrappers 脚本避免 SSL 错误。\npython arxiv_api.py \"your keywords here\" -n 10\n第六步：综合并解释\n收集所有必要信息后，建议按照以下模板，结构化、简明地撰写解释：\n思路\n：对 alpha 策略的高层次总结。\n数据使用理由\n：解释为何选择每个数据字段及其代表含义。\n运算符使用理由\n：逐步说明运算符如何转换数据以生成最终信号。\n进一步启发\n：基于你的研究，提出新的 alpha 思路。\n故障排查\nSSL 错误\n：如果运行访问互联网的 python 脚本时遇到 CERTIFICATE_VERIFY_FAILED 错误，请使用\nAI创建必要\n脚本执行命令。\n附录A：理解向量数据\n向量数据是一种特殊类型的数据字段，每天每个标的记录的事件数量可以不同。与标准矩阵数据（每天每个标的一个值）不同。\n例如，新闻情绪数据通常是向量型，因为一只股票一天可能有多篇新闻。要在大多数 BRAIN 运算符中使用这类数据，必须先用向量运算符将其聚合为单一值。",
    "===================================================================================\n先把表达式拆成「数据字段」和「运算符」两大块，就像拆零件一样理清楚基本构成。\n接着用 MCP 工具查数据字段：明确股票类型、地区等参数，分清是每天一个值的矩阵数据，还是多个值的向量数据（比如新闻情绪这类），向量数据得先聚合才能用。\n然后搞懂运算符：用工具查每个运算符的功能，知道它们是怎么加工数据的。\n遇到复杂点的就翻官方文档，还可以搜相关学术论文找灵感。最后把这些信息串起来，说清策略思路、用了啥数据、怎么运算的，就能慢慢入门 Alpha 分析。感谢老师的mcp工作流分享",
    "老师，brain-platform-mcp  在哪里下载呢",
    "SH67409\n已有热心顾问在论坛分享，请查看一些最近的帖子",
    "感谢老师提供的MCP思路， 我之前使用AI进行辅助学习ALpha 表达示的基本版 就是通过简单的提示词来做引导。\n{\n你现在是我的Alpha 表达示分析助手  我一般会这样问：\nanl69_best_eps_4wk_chg：Dividend per share 4 wk Chg\nts_mean(winsorize(ts_backfill(vec_sum(anl69_best_eps_4wk_chg), 120), std=4), 120)\n然后你要按下面的要求回复。\n要求：\n1. 理念：用一句话概括策略核心思想\n2. 数据理由：解释每个数据字段的含义、计算方式和选用原因\n3. 运算理由：解释每个运算符的功能和参数设置逻辑\n4. 输出格式：\n- 先完整中文分析\n- 后完整英文分析\n- 严格使用```chinese和```english标记代码块\n- english 需要严格的格式\nIdea:\n(CONTEXT)\nRationale for data used:\n(CONTEXT)\nRationale for operators used:\n(CONTEXT)\n5. 保持简洁，无额外内容\n6. 英文内容在100字左右。\n如果明白了，请回复，OK，I am ready\n}\n这次老师给了一个很好的借用大模型的能力来做ALpha 自动化的思路, 可以试试。\n初步思路：\n1. 获取一个字段或者多个字段， 或者找到一阶里有信息的字段。\n2. 对字段（以及表达示）做拆解，进行解释\n3. 对源始字段做不同的特征工程，\n4、获得回测的数据进行 剪枝，再回测。\n5. 制定一个弹性的筛选Alpha 的标准，\n6. 筛选后的ALpha 列表信息将发送邮件给自己，进行查看。\n试试看这个流程是否能打通。",
    "MCP确实用起来不错，让它写了几个模板跑出来的效果还算不错。这种模板会不会有过拟合的风险，比如：它给我的这个模板：\ngroup_neutralize(ts_delta(\n{\ndatafield\n}\n, {decay), sector)",
    "FG26814\n不错不错。建议在尝试的时候，先一步步做，看看效果。最后大致满意，就变成一个工作流文档。",
    "可以把operator做成json文件，datasets可以下载到本地，让大模型去读取理解",
    "很不错的想法，希望能有更多人来使用这个功能，并总结出更多经验供大家学习",
    "感谢各位大佬的分享，集思广益，让大家的MCP更加智能，高效生成alpha",
    "目前还在对MCP的摸索阶段，感谢大佬们的精彩分享，希望能把这些精华都吸收进去，创新出好的模版",
    "感谢大家的分析，受益匪浅！",
    "老师，这个流程有点像是完成的prompt工程，请问这个流程应该怎么使用呢？是放在md里面交个mcp去读取吗？",
    "通过这个文章和评论让我受益匪浅，也去摸索一下，共勉",
    "SK10818\n是的，输入框直接输入，使用xxxx.md工作流，为xxxxx(表达式)输出描述\n#========= WORLDQUANT BRAIN CONSULTANT ========== #\n# Alpha∞ Engine Status: ONLINE [♦♦♦♦♦♦♦♦♦♦] 100%\n# sys.setrecursionlimit(α∞)\n# PnL = ∑(Robustness * Creativity)\n#无限探索、鲁棒性优先，创新性增值\n#=================奋进的小徐=======================#"
  ]
}