{
  "title": "[MCP]免费最强版 -- 实现本地化趋势评分（trendScore）分析方案(附代码)",
  "description": "先赞后看，福报满满 强烈推荐前文： 1. [MCP]免费最强版 Trae/VsCode + Cline + Gemini-cli 构建 cnhkmcp 使用环境...",
  "post_body": "先赞后看，福报满满\n强烈推荐前文：\n1. [MCP]免费最强版 Trae/VsCode + Cline + Gemini-cli 构建 cnhkmcp 使用环境\nhttps://support.worldquantbrain.com/hc/zh-cn/community/posts/34338855618583\n2. [MCP]免费最强版实践--引入MCP研究员打造AI因子全流程架构(附工作流)\nhttps://support.worldquantbrain.com/hc/zh-cn/community/posts/34376106607767\n由于\ncnhkmcp\n的\ntrendScore\n服务因高频请求导致执行队列拥堵，常规优化（如调整Gemini 2.5 Pro的会话超时、MCP工具超时参数）无法解决响应超时问题。基于\nGemini 2.5 Pro\n的分布式计算建议，通过分步重构算法逻辑，实现本地化全流程闭环\n流程： 读取本地数据库 ->增量下载数据->存储数据库-> 从本地数据库读取数据、分析数据、生成报告， 分析生成完全复刻cnhkmcp内trendScore算法。\n报告示例：\n# Alpha 趋势与价值分析报告\n**报告生成于:** 2025-08-24 20:21:36\n**分析起始日期:** 2025-07-01\n## 一. 投资组合健康度摘要 (本地计算)\n| 指标 | 数值 |\n|:---|:---|\n| **投资组合趋势分** | **17379740.8549** |\n| 分析的Alpha总数 | 167 |\n| 活跃Alpha总数 | 167 |\n| - Regular Alphas | 141 |\n| - Super Alphas | 26 |\n| 组合多样性分数 | 0.5373 |\n| 总 PnL (IS) | 1638952482.00 |\n| 平均换手率 (IS) | 0.0993 |\n## 二. 投资组合详细分析 (本地计算)\n### 1. 投资组合趋势分构成\n此分数为本地计算的综合指标，旨在衡量您的 **整体 Alpha 投资组合** 的健康状况和价值。\n### 2. 月度数据分析\n| 月份 | 提交数 | 活跃数 | 总PnL | 平均换手率 | 多样性分 | S_A | S_P | S_H |\n|:---|---:|---:|---:|---:|---:|---:|---:|---:|\n| 2025-07 | 75 | 75 | 833947866.00 | 0.0866 | 0.0720 | 0.2286 | 0.3284 | 0.9591 |\n| 2025-08 | 92 | 92 | 805004616.00 | 0.1096 | 0.1247 | 0.5211 | 0.2687 | 0.8907 |\n## 三. 价值因子趋势分 (本地复现)\n此部分展示了在本地复现的官方 `value_factor_trendScore` 计算结果，该分数衡量了您在指定时间段内提交的 **Regular Alphas** 的研究多样性和深度。\n| 指标 | 数值 | 描述 |\n|:---|:---|:---|\n| **多样性总分 (Diversity Score)** | **0.1895** | **S_A * S_P * S_H** |\n| Atom 比例 (S_A) | 0.3759 | Atom Alpha 占 Regular Alpha 总数的比例 (A/N) |\n| 金字塔覆盖度 (S_P) | 0.5373 | 覆盖的独特金字塔占总数的比例 (P/P_max) |\n| 金字塔均衡度 (S_H) | 0.9385 | Alpha 在不同金字塔上分布的均匀程度 (基于熵) |\n| --- | --- | --- |\n| Regular Alpha 总数 (N) | 141 | 统计周期内的 Regular Alpha 提交总数 |\n| Atom Alpha 数量 (A) | 53 | 被标记为 'Atom' 的 Alpha 数量 |\n| 覆盖的金字塔数 (P) | 36 | 提交的 Alpha 所覆盖的独特金字塔数量 |\n| 金字塔总数 (P_max) | 67 | (本地配置值) |\n### 各金字塔 Alpha 分布\n| 金字塔名称 | Alpha 数量 |\n|:---|---:|\n| EUR/D1/ANALYST | 21 |\n| GLB/D1/MODEL | 16 |\n| GLB/D1/PV | 15 |\n| EUR/D1/PV | 14 |\n| ASI/D1/PV | 11 |\n| GLB/D1/RISK | 11 |\n| USA/D1/RISK | 11 |\n| EUR/D1/FUNDAMENTAL | 10 |\n| ASI/D1/RISK | 8 |\n| EUR/D1/RISK | 8 |\n| USA/D1/PV | 8 |\n| EUR/D1/MODEL | 7 |\n| USA/D1/ANALYST | 6 |\n| USA/D1/FUNDAMENTAL | 6 |\n| USA/D1/SENTIMENT | 6 |\n| EUR/D1/OTHER | 5 |\n| ASI/D1/FUNDAMENTAL | 5 |\n| USA/D1/INSTITUTIONS | 5 |\n| GLB/D1/FUNDAMENTAL | 4 |\n| ASI/D1/MODEL | 4 |\n| ASI/D1/ANALYST | 4 |\n| USA/D1/OPTION | 4 |\n| USA/D1/MODEL | 4 |\n| EUR/D1/SENTIMENT | 4 |\n| ASI/D1/INSTITUTIONS | 3 |\n| ASI/D1/OTHER | 3 |\n| ASI/D1/NEWS | 3 |\n| USA/D1/SOCIALMEDIA | 3 |\n| USA/D1/NEWS | 3 |\n| USA/D1/OTHER | 3 |\n| USA/D1/SHORTINTEREST | 3 |\n| EUR/D1/NEWS | 3 |\n| EUR/D1/INSTITUTIONS | 3 |\n| EUR/D1/SHORTINTEREST | 3 |\n| GLB/D1/ANALYST | 1 |\n| ASI/D1/SENTIMENT | 1 |\n## 四. 动态建议\n- **表现良好**: 您的各项指标表现均衡，请继续保持并探索新的机会。\n代码：\n1. 需要实现自己的用户名和密码读取\n2. 导入模块换成自己的cnhkmcp\nimport json\nimport asyncio\nfrom datetime import datetime, timedelta\nfrom collections import defaultdict\nimport math\nimport sqlite3\nfrom cnhkmcp.cnhkmcp.untracked.platform_functions import BrainApiClient\n# --- 配置常量 ---\nP_MAX_CONFIG = 67\ndef is_atom_local(detail):\nifnotdetailornotisinstance(detail, dict):\nreturnFalse\nclassifications_str=detail.get('classifications', '[]')\ntags_str=detail.get('tags', '[]')\ntry:\nclassifications=json.loads(classifications_str) ifisinstance(classifications_str, str) elseclassifications_str\nexceptjson.JSONDecodeError:\nclassifications= []\ntry:\ntags=json.loads(tags_str) ifisinstance(tags_str, str) elsetags_str\nexceptjson.JSONDecodeError:\ntags= []\nifnotisinstance(classifications, list): classifications= []\nifnotisinstance(tags, list): tags= []\nforcinclassifications:\ncid= (c.get('id') orc.get('name') or'')\nifisinstance(cid, str) and'SINGLE_DATA_SET'incid:\nreturnTrue\nfortintags:\nifisinstance(t, str) andt.strip().lower() =='atom':\nreturnTrue\nforcinclassifications:\ncid= (c.get('id') orc.get('name') or'')\nifisinstance(cid, str) and'ATOM'incid.upper():\nreturnTrue\nreturnFalse\nDB_NAME = './data/submited_alphas.db'\nTABLE_NAME = 'user_alphas'\nALPHA_COLUMNS = {\n'id': 'TEXT PRIMARY KEY', 'type': 'TEXT', 'author': 'TEXT',\n'dateCreated': 'TEXT', 'dateSubmitted': 'TEXT', 'dateModified': 'TEXT',\n'name': 'TEXT', 'color': 'TEXT', 'category': 'TEXT', 'tags': 'TEXT',\n'classifications': 'TEXT', 'grade': 'TEXT', 'stage': 'TEXT', 'status': 'TEXT',\n'settings': 'TEXT', 'regular_code': 'TEXT', 'regular_description': 'TEXT',\n'regular_operatorCount': 'INTEGER', 'combo_code': 'TEXT', 'combo_description': 'TEXT',\n'combo_operatorCount': 'INTEGER', 'selection_code': 'TEXT',\n'selection_description': 'TEXT', 'selection_operatorCount': 'INTEGER',\n'is_pnl': 'REAL', 'is_bookSize': 'REAL', 'is_longCount': 'INTEGER',\n'is_shortCount': 'INTEGER', 'is_turnover': 'REAL', 'is_returns': 'REAL',\n'is_drawdown': 'REAL', 'is_margin': 'REAL', 'is_sharpe': 'REAL',\n'is_fitness': 'REAL', 'is_startDate': 'TEXT', 'is_selfCorrelation': 'REAL',\n'is_prodCorrelation': 'REAL', 'is_checks': 'TEXT', 'os_startDate': 'TEXT',\n'os_osISSharpeRatio': 'REAL', 'os_preCloseSharpeRatio': 'REAL',\n'os_checks': 'TEXT', 'pyramids_list': 'TEXT', 'pyramidThemes_effective': 'INTEGER',\n'pyramidThemes_pyramids': 'TEXT', 'is_atom': 'INTEGER'\n}\nasync def fetch_and_store_all_alphas(start_date_str, end_date_str):\ndb=SQLiteHelper(DB_NAME)\ndb.create_table(TABLE_NAME, ALPHA_COLUMNS)\ntry:\nexisting_alphas=db.query_data(f\"SELECT id FROM {TABLE_NAME}\")\nexisting_ids= {alpha['id'] foralphainexisting_alphas}\nprint(f\"Found {len(existing_ids)} existing alpha IDs in the database.\")\nexceptsqlite3.OperationalError:\nexisting_ids=set()\nprint(\"No existing alphas table found, starting fresh.\")\nbrain_client=BrainApiClient()\nwithopen('user_info.txt', 'r') asf:\ndata=f.read().strip().split('\\n')\nuser_data= {line.split(': ')[0]: line.split(': ')[1] forlineindata}\nawaitbrain_client.c(user_data['username'][1:-1], user_data['password'][1:-1])\nall_alpha_ids= []\noffset=0\nlimit=100\nwhileTrue:\nprint(f\"Fetching alpha IDs from offset {offset}...\")\ntry:\nalphas_resp=awaitbrain_client.get_user_alphas(\nstage='OS', limit=limit, offset=offset,\nsubmission_start_date=start_date_str, submission_end_date=end_date_str\n)\nifnotalphas_respor'results'notinalphas_resp:\nprint(\"No more alpha IDs or error in response.\")\nbreak\ncurrent_ids= [a.get('id') forainalphas_resp['results'] ifa.get('id')]\nall_alpha_ids.extend(current_ids)\nprint(f\"Fetched {len(current_ids)} IDs. Total IDs: {len(all_alpha_ids)}\")\nifnotalphas_resp.get('next'):\nprint(\"Reached the last page of alpha IDs.\")\nbreak\noffset+=limit\nawaitasyncio.sleep(0.2)\nexceptExceptionase:\nprint(f\"Error fetching alpha IDs: {e}\")\nbreak\nprint(f\"Total unique alpha IDs to process: {len(all_alpha_ids)}\")\nnew_alpha_ids= [alpha_idforalpha_idinall_alpha_idsifalpha_idnotinexisting_ids]\nprint(f\"Found {len(new_alpha_ids)} new alphas to fetch details for.\")\nifnotnew_alpha_ids:\nprint(\"No new alphas to process. Skipping detail fetching.\")\ndb.close()\nreturn\ntasks= [brain_client.get_alpha_details(alpha_id) foralpha_idinnew_alpha_ids]\nchunk_size=20\ntotal_chunks= (len(tasks) +chunk_size-1) //chunk_size\ntotal_inserted=0\nforiinrange(0, len(tasks), chunk_size):\nchunk_num=i//chunk_size+1\nprint(f\"Processing chunk {chunk_num}/{total_chunks}...\")\nchunk=tasks[i:i+chunk_size]\nresults=awaitasyncio.gather(*chunk, return_exceptions=True)\nalphas_in_chunk= [process_alpha_data(d) fordinresultsifnotisinstance(d, Exception) andd]\nifalphas_in_chunk:\ndb.insert_many_data(TABLE_NAME, alphas_in_chunk)\ntotal_inserted+=len(alphas_in_chunk)\nprint(f\" -> Stored {len(alphas_in_chunk)} alphas from chunk {chunk_num} to the database.\")\nelse:\nprint(f\" -> No valid alpha details in chunk {chunk_num} to store.\")\nawaitasyncio.sleep(0.5)\nprint(f\"\\nTotal new alphas inserted/updated in this run: {total_inserted}\")\ndb.close()\nprint(\"Database connection closed.\")\ndef process_alpha_data(alpha_data):\nprocessed= {k: NoneforkinALPHA_COLUMNS.keys()}\nforkey, valueinalpha_data.items():\nifkeyinALPHA_COLUMNS:\nifisinstance(value, (dict, list)):\nprocessed[key] =json.dumps(value)\nelse:\nprocessed[key] =value\ndefflatten_and_assign(nested_dict, prefix):\nifnotisinstance(nested_dict, dict): return\nforkey, valueinnested_dict.items():\nfield_name=f\"{prefix}_{key}\"\niffield_nameinALPHA_COLUMNS:\nifisinstance(value, (dict, list)):\nprocessed[field_name] =json.dumps(value)\nelse:\nprocessed[field_name] =value\nifalpha_data.get('type') =='REGULAR'and'regular'inalpha_data:\nflatten_and_assign(alpha_data['regular'], 'regular')\nelifalpha_data.get('type') =='SUPER':\nif'combo'inalpha_data:\nflatten_and_assign(alpha_data['combo'], 'combo')\nif'selection'inalpha_data:\nflatten_and_assign(alpha_data['selection'], 'selection')\nif'is'inalpha_data:\nflatten_and_assign(alpha_data['is'], 'is')\nif'os'inalpha_data:\nflatten_and_assign(alpha_data['os'], 'os')\npyramid_names= []\nifisinstance(alpha_data.get('pyramids'), list):\npyramid_names.extend([p.get('name') forpinalpha_data['pyramids'] ifp.get('name')])\nelif'pyramidThemes'inalpha_dataandisinstance(alpha_data['pyramidThemes'].get('pyramids'), list):\npyramid_names.extend([p.get('name') forpinalpha_data['pyramidThemes']['pyramids'] ifp.get('name')])\nprocessed['pyramids_list'] =json.dumps(pyramid_names)\nif'pyramidThemes'inalpha_data:\nif'pyramidThemes_effective'inALPHA_COLUMNS:\nprocessed['pyramidThemes_effective'] =alpha_data['pyramidThemes'].get('effective')\nif'pyramidThemes_pyramids'inALPHA_COLUMNS:\nprocessed['pyramidThemes_pyramids'] =json.dumps(alpha_data['pyramidThemes'].get('pyramids', []))\nprocessed['is_atom'] =1ifis_atom_local(alpha_data) else0\nreturnprocessed\ndef calculate_local_trend_score(alphas):\nregular_alphas= [aforainalphasifa.get('type') =='REGULAR']\nN=len(regular_alphas)\nifN==0:\nreturn {'diversity_score': 0.0, 'N': 0, 'A': 0, 'P': 0, 'P_max': P_MAX_CONFIG, 'S_A': 0.0, 'S_P': 0.0, 'S_H': 0.0, 'per_pyramid_counts': {}}\natom_count=0\nper_pyramid=defaultdict(int)\ntotal_pyramid_occurrences=0\nforalphainregular_alphas:\nifalpha.get('is_atom') ==1:\natom_count+=1\npyramids_list_str=alpha.get('pyramids_list', '[]')\ntry:\npyramids=json.loads(pyramids_list_str)\nifisinstance(pyramids, list):\nforp_nameinpyramids:\nper_pyramid[p_name] +=1\ntotal_pyramid_occurrences+=1\nexceptjson.JSONDecodeError:\ncontinue\nA=atom_count\nP=len(per_pyramid)\nP_max=P_MAX_CONFIG\nS_A= (A/N) ifN>0else0.0\nS_P= (P/P_max) ifP_max>0else0.0\nS_H=0.0\nifP>1andtotal_pyramid_occurrences>0:\nH=0.0\nforcountinper_pyramid.values():\nq=count/total_pyramid_occurrences\nifq>0:\nH-=q*math.log2(q)\nmax_H=math.log2(P)\nS_H=H/max_Hifmax_H>0else0.0\ndiversity_score=S_A*S_P*S_H\nreturn {'diversity_score': diversity_score, 'N': N, 'A': A, 'P': P, 'P_max': P_max, 'S_A': S_A, 'S_P': S_P, 'S_H': S_H, 'per_pyramid_counts': dict(per_pyramid)}\ndef analyze_alphas_locally(alphas, start_date_str):\nmcp_trend_score_result=calculate_local_trend_score(alphas)\ntotal_alphas=len(alphas)\nactive_regular_alphas, active_super_alphas=0, 0\nunique_pyramids=set()\ntotal_pnl, total_turnover=0.0, 0.0\nmonthly_data=defaultdict(lambda: {\n'total_alphas': 0, 'active_alphas': 0, 'pnl': 0, 'turnover': 0,\n'regular_alphas': [] # 存储每个月完整的 Regular Alpha 字典\n})\nforalphainalphas:\ntotal_pnl+=alpha.get('is_pnl', 0) or0\ntotal_turnover+=alpha.get('is_turnover', 0) or0\nifalpha.get('status') =='ACTIVE':\nifalpha.get('type') =='REGULAR':\nactive_regular_alphas+=1\nelifalpha.get('type') =='SUPER':\nactive_super_alphas+=1\npyramids_list_str=alpha.get('pyramids_list', '[]')\ntry:\npyramids=json.loads(pyramids_list_str)\nforp_nameinpyramids:\nunique_pyramids.add(p_name)\nexceptjson.JSONDecodeError:\npass\nsubmission_date_str=alpha.get('dateSubmitted')\nifsubmission_date_str:\ntry:\nsubmission_date=datetime.fromisoformat(submission_date_str.replace('Z', '+00:00'))\nmonth_key=submission_date.strftime('%Y-%m')\nmonthly_data[month_key]['total_alphas'] +=1\nmonthly_data[month_key]['pnl'] +=alpha.get('is_pnl', 0) or0\nmonthly_data[month_key]['turnover'] +=alpha.get('is_turnover', 0) or0\nifalpha.get('status') =='ACTIVE':\nmonthly_data[month_key]['active_alphas'] +=1\nifalpha.get('type') =='REGULAR':\n# 存储完整的 alpha 字典\nmonthly_data[month_key]['regular_alphas'].append(alpha)\nexcept (ValueError, TypeError):\npass\n# 逐月计算多样性分数\nformonth, datainmonthly_data.items():\n# 现在传入的是完整的 alpha 列表，calculate_local_trend_score 可以正确处理\nmonthly_diversity_results=calculate_local_trend_score(data['regular_alphas'])\ndata['diversity_score'] =monthly_diversity_results['diversity_score']\ndata['S_A'] =monthly_diversity_results['S_A']\ndata['S_P'] =monthly_diversity_results['S_P']\ndata['S_H'] =monthly_diversity_results['S_H']\ndiversity_score=len(unique_pyramids) /P_MAX_CONFIGifP_MAX_CONFIG>0else0\ntotal_active_alphas=active_regular_alphas+active_super_alphas\nportfolio_trend_score=0\niftotal_active_alphas>0:\npnl_per_active_alpha=total_pnl/total_active_alphas\nportfolio_trend_score=pnl_per_active_alpha*diversity_score*math.log(active_super_alphas+1)\nreturn {\n\"total_alphas\": total_alphas, \"active_regular_alphas\": active_regular_alphas,\n\"active_super_alphas\": active_super_alphas, \"total_active_alphas\": total_active_alphas,\n\"unique_pyramids_count\": len(unique_pyramids), \"P_max\": P_MAX_CONFIG,\n\"diversity_score\": diversity_score, \"total_pnl\": total_pnl,\n\"average_turnover\": total_turnover/total_alphasiftotal_alphas>0else0,\n\"portfolio_trend_score\": portfolio_trend_score,\n\"report_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n\"analysis_start_date\": start_date_str,\n\"monthly_data\": dict(sorted(monthly_data.items())),\n\"mcp_trend_score_result\": mcp_trend_score_result\n}\ndef generate_dynamic_recommendations(results):\nrecommendations= []\nmcp_results=results.get(\"mcp_trend_score_result\", {})\nifmcp_results:\nifmcp_results.get('S_A', 0) <0.2:\nrecommendations.append(\"- **提升Atom比例 (S_A)**: 您当前的Atom Alpha比例较低。请专注于开发更多基于单一数据集的Atom策略，以深化您的研究基础。\")\nifmcp_results.get('S_P', 0) <0.3:\nrecommendations.append(\"- **扩大金字塔覆盖 (S_P)**: 您的策略过于集中。请分析`各金字塔Alpha分布`表，并尝试在覆盖数量为0或较少的金字塔上开发新策略。\")\nifmcp_results.get('S_H', 0) <0.5:\nrecommendations.append(\"- **均衡金字塔分布 (S_H)**: 您的Alpha在不同金字塔上的分布不够均衡。请关注那些已有覆盖但数量不多的金字塔，增加其策略数量以提升均衡度。\")\nifresults.get(\"active_super_alphas\", 0) ==0:\nrecommendations.append(\"- **启用Super Alphas**: 您目前没有活跃的Super Alphas。尝试将您的高质量Regular Alphas组合成Super Alpha，可以显著提升您的投资组合趋势分。\")\nifresults.get(\"average_turnover\", 0) >0.6:\nrecommendations.append(\"- **优化换手率**: 您的投资组合平均换手率偏高({:.2f})，这可能增加交易成本。请检查高换手率的Alpha并考虑优化。\".format(results[\"average_turnover\"]))\nifnotrecommendations:\nrecommendations.append(\"- **表现良好**: 您的各项指标表现均衡，请继续保持并探索新的机会。\")\nreturnrecommendations\ndef generate_report(results):\nifnotresults:\nprint(\"没有结果可以生成报告。\")\nreturn\nmcp_results=results.get(\"mcp_trend_score_result\", {})\nmcp_section=\"## 三. 价值因子趋势分 (本地复现)\\n\\n\"\nifmcp_results:\nmcp_section+=\"此部分展示了在本地复现的官方 `value_factor_trendScore` 计算结果，该分数衡量了您在指定时间段内提交的 **Regular Alphas** 的研究多样性和深度。\\n\\n\"\nmcp_section+=\"| 指标 | 数值 | 描述 |\\n\"\nmcp_section+=\"|:---|:---|:---|\\n\"\nmcp_section+=f\"| **多样性总分 (Diversity Score)** | **{mcp_results.get('diversity_score', 0):.4f}** | **S_A * S_P * S_H** |\\n\"\nmcp_section+=f\"| Atom 比例 (S_A) | {mcp_results.get('S_A', 0):.4f} | Atom Alpha 占 Regular Alpha 总数的比例 (A/N) |\\n\"\nmcp_section+=f\"| 金字塔覆盖度 (S_P) | {mcp_results.get('S_P', 0):.4f} | 覆盖的独特金字塔占总数的比例 (P/P_max) |\\n\"\nmcp_section+=f\"| 金字塔均衡度 (S_H) | {mcp_results.get('S_H', 0):.4f} | Alpha 在不同金字塔上分布的均匀程度 (基于熵) |\\n\"\nmcp_section+=\"| --- | --- | --- |\\n\"\nmcp_section+=f\"| Regular Alpha 总数 (N) | {mcp_results.get('N', 0)} | 统计周期内的 Regular Alpha 提交总数 |\\n\"\nmcp_section+=f\"| Atom Alpha 数量 (A) | {mcp_results.get('A', 0)} | 被标记为 'Atom' 的 Alpha 数量 |\\n\"\nmcp_section+=f\"| 覆盖的金字塔数 (P) | {mcp_results.get('P', 0)} | 提交的 Alpha 所覆盖的独特金字塔数量 |\\n\"\nmcp_section+=f\"| 金字塔总数 (P_max) | {mcp_results.get('P_max', 0)} | (本地配置值) |\\n\\n\"\nper_pyramid_counts=mcp_results.get('per_pyramid_counts', {})\nifper_pyramid_counts:\nmcp_section+=\"### 各金字塔 Alpha 分布\\n\\n| 金字塔名称 | Alpha 数量 |\\n|:---|---:|\\n\"\nsorted_pyramids=sorted(per_pyramid_counts.items(), key=lambdaitem: item[1], reverse=True)\nforname, countinsorted_pyramids:\nmcp_section+=f\"| {name} | {count} |\\n\"\nelse:\nmcp_section+=\"无法在本地计算价值因子趋势分。\\n\"\nmonthly_report_section=\"### 2. 月度数据分析\\n\\n| 月份 | 提交数 | 活跃数 | 总PnL | 平均换手率 | 多样性分 | S_A | S_P | S_H |\\n|:---|---:|---:|---:|---:|---:|---:|---:|---:|\\n\"\nifresults.get(\"monthly_data\"):\nformonth, datainresults[\"monthly_data\"].items():\navg_turnover=data['turnover'] /data['total_alphas'] ifdata['total_alphas'] >0else0\nmonthly_report_section+= (f\"| {month} | {data['total_alphas']} | {data['active_alphas']} | \"\nf\"{data['pnl']:.2f} | {avg_turnover:.4f} | \"\nf\"{data.get('diversity_score', 0):.4f} | {data.get('S_A', 0):.4f} | \"\nf\"{data.get('S_P', 0):.4f} | {data.get('S_H', 0):.4f} |\\n\")\nelse:\nmonthly_report_section+=\"| 无可用月度数据 | - | - | - | - | - | - | - | - |\\n\"\nrecommendations_list=generate_dynamic_recommendations(results)\nrecommendations_section=\"## 四. 动态建议\\n\\n\"+\"\\n\".join(recommendations_list)\nreport_content=f\"\"\"\n# Alpha 趋势与价值分析报告\n**报告生成于:** {results['report_date']}\n**分析起始日期:** {results.get('analysis_start_date', 'N/A').split('T')[0]}\n## 一. 投资组合健康度摘要 (本地计算)\n| 指标 | 数值 |\n|:---|:---|\n| **投资组合趋势分** | **{results.get('portfolio_trend_score', 0):.4f}** |\n| 分析的Alpha总数 | {results.get('total_alphas', 0)} |\n| 活跃Alpha总数 | {results.get('total_active_alphas', 0)} |\n| - Regular Alphas | {results.get('active_regular_alphas', 0)} |\n| - Super Alphas | {results.get('active_super_alphas', 0)} |\n| 组合多样性分数 | {results.get('diversity_score', 0):.4f} |\n| 总 PnL (IS) | {results.get('total_pnl', 0):.2f} |\n| 平均换手率 (IS) | {results.get('average_turnover', 0):.4f} |\n## 二. 投资组合详细分析 (本地计算)\n### 1. 投资组合趋势分构成\n此分数为本地计算的综合指标，旨在衡量您的 **整体 Alpha 投资组合** 的健康状况和价值。\n{monthly_report_section}\n{mcp_section}\n{recommendations_section}\n\"\"\"\nreport_filename=f\"alpha_trend_report_{datetime.now().strftime('%Y%m%d')}.md\"\nwithopen(report_filename, 'w', encoding='utf-8') asf:\nf.write(report_content)\nprint(f\"成功生成分析报告: {report_filename}\")\nclass SQLiteHelper:\ndef__init__(self, db_name):\nself.conn=sqlite3.connect(db_name)\nself.cursor=self.conn.cursor()\ndefcreate_table(self, table_name, columns):\ncolumns_def=', '.join([f'{col}{dtype}'forcol, dtypeincolumns.items()])\nsql=f'CREATE TABLE IF NOT EXISTS {table_name} ({columns_def})'\nself.cursor.execute(sql)\nself.conn.commit()\ndefinsert_many_data(self, table_name, data_list):\nifnotdata_list:\nreturn\ncolumns=', '.join(data_list[0].keys())\nplaceholders=', '.join(['?'] *len(data_list[0]))\nsql=f'INSERT OR REPLACE INTO {table_name} ({columns}) VALUES ({placeholders})'\nvalues= [tuple(item.get(col, None) forcolindata_list[0].keys()) foritemindata_list]\nself.cursor.executemany(sql, values)\nself.conn.commit()\ndefquery_data(self, sql, params=None):\nself.cursor.execute(sql, paramsor ())\ncolumns= [description[0] fordescriptioninself.cursor.description]\nreturn [dict(zip(columns, row)) forrowinself.cursor.fetchall()]\ndefclose(self):\nself.cursor.close()\nself.conn.close()\ndef main(start_date, end_date):\ntry:\nloop=asyncio.get_running_loop()\nexceptRuntimeError:\nloop=asyncio.new_event_loop()\nasyncio.set_event_loop(loop)\nloop.run_until_complete(fetch_and_store_all_alphas(start_date, end_date))\nprint(\"Data fetching complete. Proceeding with local analysis.\")\ndb=SQLiteHelper(DB_NAME)\ntry:\nall_alphas=db.query_data(f\"SELECT * FROM {TABLE_NAME}\")\nifnotall_alphas:\nprint(\"No alphas found in the database. Will generate a report with zeroed local stats.\")\nall_alphas= []\nprint(f\"Loaded {len(all_alphas)} alphas from the database for analysis.\")\nanalysis_results=analyze_alphas_locally(all_alphas, start_date)\ngenerate_report(analysis_results)\nfinally:\ndb.close()\nprint(\"Database connection for analysis closed.\")\nif __name__ == \"__main__\":\nstart_date=\"2025-07-01T23:59:59Z\"\nend_date=\"2025-08-24T23:59:59Z\"\nmain(start_date, end_date)",
  "post_comments": [
    "就是代码格式有点奇怪【捂脸】",
    "大佬，有调整过格式的代码吗？这个格式太难调整了。。。"
  ]
}